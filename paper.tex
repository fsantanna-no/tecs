% v2-acmsmall-sample.tex, dated March 6 2012
% This is a sample file for ACM small trim journals
%
% Compilation using 'acmsmall.cls' - version 1.3 (March 2012), Aptara Inc.
% (c) 2010 Association for Computing Machinery (ACM)
%
% Questions/Suggestions/Feedback should be addressed to => "acmtexsupport@aptaracorp.com".
% Users can also go through the FAQs available on the journal's submission webpage.
%
% Steps to compile: latex, bibtex, latex latex
%
% For tracking purposes => this is v1.3 - March 2012

\documentclass[prodmode,acmtecs]{acmsmall} % Aptara syntax

\usepackage{amsmath}
\usepackage{dsfont}
\usepackage{mathtools}
\everymath{\displaystyle}

\usepackage{verbatim}
\usepackage{xspace}
\newcommand{\C}{\emph{C}\xspace}
\newcommand{\VM}{\emph{VM}\xspace}
\newcommand{\CEU}{\textsc{C\'{e}u}\xspace}
\newcommand{\code}[1] {{\small{\texttt{#1}}}}
\newcommand{\MM}[1] {\textcircled{\tiny{\textsf{#1}}}}

\newcommand{\ST}{\1\xrightarrow[~n~]{}\1}
\newcommand{\BT}{\xRightarrow[(i,E)]{}}
\newcommand{\LL}{\langle}
\newcommand{\RR}{\rangle}
\newcommand{\DS}{\displaystyle}
\newcommand{\rr}[1] {{\textbf{\scriptsize{#1}}}}

\newcommand{\1}{\;}
\newcommand{\2}{\;\;}
\newcommand{\3}{\;\;\;}
\newcommand{\5}{\;\;\;\;\;}
\newcommand{\ten}{\5\5}
\newcommand{\twenty}{\ten\ten}

\usepackage{color}
\definecolor{light}{gray}{0.87}
\definecolor{dark}{gray}{0.30}
%\definecolor{light}{rgb}{.90,.90,.90}
\definecolor{darkgreen}{rgb}{0,.50,0}
\definecolor{darkblue}{rgb}{0,0,.50}
\definecolor{darkred}{rgb}{.50,0,0}
\definecolor{darkpur}{rgb}{.50,0,.50}

\usepackage{listings}
%\usepackage{textcomp}
\usepackage{url}
\lstset{
%columns=fullflexible,
%basicstyle=\ttfamily,
escapeinside={||},
    %mathescape=true,
    language=C, % choose the language of the code
    basicstyle=\fontfamily{pcr}\selectfont\scriptsize\color{black},
    keywordstyle=\color{black}\bfseries, % style for keywords
    numbers=none, % where to put the line-numbers
    numberstyle=\tiny, % the size of the fonts that are used for the line-numbers
    backgroundcolor=\color{light},
    showspaces=false, % show spaces adding particular underscores
    showstringspaces=false, % underline spaces within strings
    showtabs=false, % show tabs within strings adding particular underscores
    %frame=single, % adds a frame around the code
    tabsize=2, % sets default tabsize to 2 spaces
    %rulesepcolor=\color{gray}
    captionpos=b, % sets the caption-position to bottom
    breaklines=false, % sets automatic line breaking
    %breakatwhitespace=false,
    numbersep=2em,
    % C was used in the blocksworld example to refer to block C and nowhere else
    emph={par,or,hor,do,end,loop,await,emit,input,event,call,with,%
          var,and,then,else,return,pure,deterministic,nohold,finalize,%
          class, every, FOREVER, this, spawn, in, pool, watching, until, 
          interface, each, abort, when, signal, PROC, CHAN, SIGNAL, PAR, not,
          bool, data, tag, escape, new, traverse,implementation,output,
          native,@const,@pure,@safe,define},
    emphstyle={\bfseries},
    commentstyle=\color{dark}\scriptsize,
    %xleftmargin=20pt,
    %xrightmargin=20pt,
    framesep=20pt,
    %upquote=true,
    %aboveskip={1.5\baselineskip},
}

% Metadata Information
%\acmVolume{9}
%\acmNumber{4}
%\acmArticle{39}
%\acmYear{2010}
%\acmMonth{3}

% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
%\doi{0000001.0000001}

%ISSN
%\issn{1234-56789}

% Document starts
\begin{document}

% Page heads
%\markboth{G. Zhou et al.}{A Multifrequency MAC Specially Designed for WSN 
%Applications}

% Title portion
\title{The Design, Semantics, and Implementation of the Synchronous Language 
\CEU}

\author{
Francisco Sant'Anna
\affil{Departamento de Inform\'atica, PUC--Rio}
Roberto Ierusalimschy
\affil{Departamento de Inform\'atica, PUC--Rio}
Noemi Rodriguez
\affil{Departamento de Inform\'atica, PUC--Rio}
Silvana Rossetto
\affil{Departamento de Ci\^encia da Computa\c{c}\~ao, UFRJ}
Adriano Branco
\affil{Departamento de Inform\'atica, PUC--Rio}
}

% NOTE! Affiliations placed here should be for the institution where the
%       BULK of the research was done. If the author has gone to a new
%       institution, before publication, the (above) affiliation should NOT be changed.
%       The authors 'current' address may be given in the "Author's addresses:" block (below).
%       So for example, Mr. Abdelzaher, the bulk of the research was done at UIUC, and he is
%       currently affiliated with NASA.

\begin{abstract}
\CEU is a reactive language inspired by Esterel that targets constrained 
embedded platforms and ensures safe concurrency by handling threats at compile 
time.
%
Based on the synchronous programming model, our design allows for a simple 
reasoning about concurrency that enables compile-time analysis and results in 
deterministic and memory-safe programs.
%
% TODO: some uses?
%
We discuss the design of \CEU and propose a formal semantics for its particular 
control mechanisms, such as parallel compositions, finalization, and internal 
events.
%
We also present two implementation back ends:
one aiming for resource efficiency and interoperability with \C,
and another based on a virtual machine that allows remote reprogramming.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
%\begin{CCSXML}
%<ccs2012>
 %<concept>
  %<concept_id>10010520.10010553.10010562</concept_id>
  %<concept_desc>Computer systems organization~Embedded systems</concept_desc>
  %<concept_significance>500</concept_significance>
 %</concept>
 %<concept>
  %<concept_id>10010520.10010575.10010755</concept_id>
  %<concept_desc>Computer systems organization~Redundancy</concept_desc>
  %<concept_significance>300</concept_significance>
 %</concept>
 %<concept>
  %<concept_id>10010520.10010553.10010554</concept_id>
  %<concept_desc>Computer systems organization~Robotics</concept_desc>
  %<concept_significance>100</concept_significance>
 %</concept>
 %<concept>
  %<concept_id>10003033.10003083.10003095</concept_id>
  %<concept_desc>Networks~Network reliability</concept_desc>
  %<concept_significance>100</concept_significance>
 %</concept>
%</ccs2012>
%\end{CCSXML}

%\ccsdesc[500]{Computer systems organization~Embedded systems}
%\ccsdesc[300]{Computer systems organization~Redundancy}
%\ccsdesc{Computer systems organization~Robotics}
%\ccsdesc[100]{Networks~Network reliability}

%
% End generated code
%

% We no longer use \terms command
%\terms{Design, Algorithms, Performance}

\keywords{
Concurrency, Determinism, Embedded Systems,
Esterel, Synchronous, Reactivity
}

%\acmformat{Gang Zhou, Yafeng Wu, Ting Yan, Tian He, Chengdu Huang, John A.  
%Stankovic,
%and Tarek F. Abdelzaher, 2010. A multifrequency MAC specially
%designed for  wireless sensor network applications.}
% At a minimum you need to supply the author names, year and a title.
% IMPORTANT:
% Full first names whenever they are known, surname last, followed by a period.
% In the case of two authors, 'and' is placed between them.
% In the case of three or more authors, the serial comma is used, that is, all author names
% except the last one but including the penultimate author's name are followed by a comma,
% and then 'and' is placed before the final author's name.
% If only first and middle initials are known, then each initial
% is followed by a period and they are separated by a space.
% The remaining information (journal title, volume, article number, date, etc.) is 'auto-generated'.

%\begin{bottomstuff}
%This work is supported by the National Science Foundation, under
%grant CNS-0435060, grant CCR-0325197 and grant EN-CS-0329609.

%Author's addresses: G. Zhou, Computer Science Department,
%College of William and Mary; Y. Wu  {and} J. A. Stankovic,
%Computer Science Department, University of Virginia; T. Yan,
%Eaton Innovation Center; T. He, Computer Science Department,
%University of Minnesota; C. Huang, Google; T. F. Abdelzaher,
%(Current address) NASA Ames Research Center, Moffett Field, California 94035.
%\end{bottomstuff}

\maketitle

\section{Introduction}

An established alternative to \C in the field of embedded systems is the family 
of reactive synchronous languages \cite{rp.twelve}.
%
Two major styles of synchronous languages have evolved:
in the \emph{control}--\emph{imperative} style, programs are structured with 
control flow primitives, such as parallelism, repetition, and preemption;
in the \emph{dataflow}--\emph{declarative} style, programs can be seen as 
graphs of values, in which a change to a value is propagated through its 
dependencies without explicit programming.
%
Considering the control-based languages, Esterel~\cite{esterel.ieee91} was the 
first to appear and succeed, influencing a number of embedded languages, such 
as \emph{Reactive-C}~\cite{rp.rc}, \emph{OSM}~\cite{wsn.osm}, 
\emph{Sync-C}~\cite{rp.synchc}, and \emph{PRET-C}~\cite{rp.pretc}.

% TODO: SCCharts?, SynchCharts?

Despite its success and influence, Esterel has an overly complex semantics that 
requires careful static analysis to detect and refuse programs with 
\emph{causality} and \emph{schizophrenia} problems.
Both problems have an extensive coverage and debate in the literature 
~\cite{esterel.constructive,esterel.d7,esterel.d6,esterel.d3,esterel.d5,esterel.d8,esterel.d1,esterel.schizo2}.
%
The complex semantics not only challenges the analysis and compilation of 
programs, but also results in incompatible and non-compliant implementations.
%
Above all, it also affects the programmer's understanding about the code, 
which, ultimately, has to solve the errors when facing corner cases.
%
Another drawback of the Esterel semantics consists of the loose and 
non-deterministic execution for intra-reaction statements, which prevents 
threads to share memory and interact with stateful system calls safely.
%
%For instance, although Esterel supports orthogonal abortion of 
%threads~\cite{esterel.preemption}, it doesn't offer an effective mechanism to 
%release resources in use.

In this work, we present \CEU, a new programming language that inherits the 
synchronous and imperative mindset of Esterel but diverges in fundamental 
semantic aspects.
%
Overall, \CEU has a simple semantics with fine-grained execution control, and a 
straightforward single-threaded implementation targeting resource-constrained 
systems.
%
The list that follows summarizes the semantic peculiarities of our design:
%
\begin{itemize}
%
\item Unique and queue-based external events, which define the notion of time 
in \CEU (Section~\ref{sec.ceu.exts}).
%
\item Stack-based internal events for intra-reaction communication, which also
provides a limited form of coroutines (Section~\ref{sec.ceu.ints}).
%
\item Static temporal analysis to detect suspicious concurrent statements 
(Section~\ref{sec.ceu.analysis}).
%
\item Safe integration with \C via function annotations and enforced 
finalization for external resources (Section~\ref{sec.ceu.c}).
%
\item First-class synchronized timers with a dedicated syntax 
(Section~\ref{sec.ceu.timers}).
\end{itemize}
%
We discuss the design of \CEU and present a formal semantics for a small 
synchronous kernel that represents a subset of the language covering these new 
functionalities.
% TODO: why? stack, fin, principalmente
%
We also present a lightweight implementation of \CEU with two back ends:
one aiming for resource efficiency and interoperability with \C,
and another based on a virtual machine that allows remote reprogramming.
%
Our implementations target resource-constrained devices, such as \emph{Arduino} 
and \emph{MICAz} sensor nodes based on 8-bit microcontrollers%
\footnote{
Both \emph{Arduino} and \emph{MICAz} use the 8-bit \emph{ATmega328} 
microcontroller with 32K of FLASH and 2K of SRAM.
}, showing that the peculiarities in the semantics of \CEU do not pose 
practical obstacles.%:\url{http://www.atmel.com/devices/atmega328.aspx}}

In previous work~\cite{ceu.sensys13,ceu.terra}, we employed \CEU in the context 
of wireless sensor networks, developing a number of applications, protocols, 
and device drivers.
%
We evaluated the expressiveness of \CEU in comparison to event-driven code in 
\C and attested a reduction in source code size (around 25\%) with a small 
increase in memory usage (around 5--10\% for \emph{text} and 
\emph{data})~\cite{ceu.sensys13}.
%
For the \VM back end, applications have a bytecode footprint in the order of 
hundreds of bytes which can be transmitted over the air in a few 
packets~\cite{ceu.terra}.

The rest of the paper is organized as follows:
Section~\ref{sec.ceu} discusses the design of \CEU, focusing on the fundamental 
differences to Esterel.
Section~\ref{sec.sem} presents a formal semantics for the control primitives of 
\CEU.
Section~\ref{sec.impl} presents the \C and \VM implementation back ends.
Section~\ref{sec.related} discusses other synchronous languages targeting 
embedded systems.
Section~\ref{sec.conclusion} concludes the paper.

%\begin{itemize}
        %\item Estendendo para outros dominios? (jogos, artigo Mod'15)
        %\item Usos: sala de aula, GSoC
%\item Semantica e Implementacao (nesse artigo, somente subset estatico)
% Artigo de Rust, nao resolve os problemas
%https://blog.skcript.com/asynchronous-io-in-rust-36b623e7b965
%state machines everywhere
%\end{itemize}

%Our work focuses on \emph{concurrency safety}, rather than \emph{type 
%safety}~\cite{wsn.safety}.%
%\footnote{
%We consider both safety aspects to be complimentary and orthogonal, i.e., 
%type-safety techniques could also be applied to \CEU.
%}

%As a trade-off, our design imposes limitations on the language expressiveness, 
%such as doing computationally-intensive operations and meeting hard real-time 
%responsiveness.

\section{The Design of \CEU}
\label{sec.ceu}

\CEU is a synchronous reactive language inspired by Esterel with support for 
multiple concurrent lines of execution known as \emph{trails}.
By reactive, we mean that programs are stimulated by the environment through 
input events, which are broadcast to all awaiting trails.
By synchronous, we mean that trails at any given moment are either reacting to 
the current event or are awaiting another event;
in other words, trails never react to different events simultaneously.

In the sections that follow, we discuss the main differences between \CEU and 
Esterel:
unique and queue-based external events (Section~\ref{sec.ceu.exts}),
stack-based internal events (Section~\ref{sec.ceu.ints}),
static temporal analysis for concurrent statements (Section~\ref{sec.ceu.analysis}),
safe integration with \C (Section~\ref{sec.ceu.c}), and
first-class synchronized timers (Section~\ref{sec.ceu.timers}).

Regarding the similarities, Figure~\ref{lst.abro} shows side-by-side the 
implementations in Esterel (a) and \CEU (b) for the following control 
specification:
%
\emph{``Emit an output O as soon as two inputs A and B have occurred.
Reset this behavior each time the input R occurs''}~\cite{esterel.primer}.
%
The first phrase of the specification, awaiting and emitting the events, is 
translated almost identically in the two languages (ln. 3--8, in both 
implementations), given that Esterel's `$\|$' and \CEU's \code{par/and} 
constructs are equivalent.
%
For the second phrase, the reset behavior, the Esterel version uses a 
\code{abort-when} (ln. 2--9), which, in this case, serves the same purpose of 
\CEU's \code{par/or} (ln. 2--11):
the occurrence of event \code{R} aborts the awaiting statements in parallel and 
restarts the enclosing \code{loop}.

% TODO: input/output declarations

\begin{figure}
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3.5em,mathescape=true]
loop
   abort
      [
         await A
      $\|$
         await B
      ];
      emit O
   when R
end

.
\end{lstlisting}
\centering\small{(a) Esterel}
\end{minipage}
%
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3.5em]
loop do
   par/or do
      par/and do
         await A;
      with
         await B;
      end
      emit O;
   with
      await R;
   end
end
\end{lstlisting}
\centering\small{(b) \CEU}
\end{minipage}
%\rule{8.4cm}{0.37pt}
\caption{ A control specification implemented in Esterel and \CEU:
\emph{``Emit \code{O} after \code{A} and \code{B}, resetting each \code{R}.''}
\label{lst.abro}
}
\end{figure}

\CEU employs the synchronous model, in which programs advance in a sequence of 
discrete reactions to external events.
%
It also has a strong imperative flavor, with explicit control flow through 
sequences, loops, and parallels, and also assignments.
%
Being designed for control-intensive applications, \CEU provides support for 
concurrent lines of execution and broadcast communication through events.
%
Internal computations within a reaction (e.g. expressions, assignments, and 
system calls) are considered to take no time in accordance with the synchronous 
hypothesis~\cite{rp.hypothesis}.
An \code{await} is the only statement that halts a running reaction and allows 
a program to advance in this notion of time.
%
To ensure that reactions run in bounded time and programs always progress, 
loops are statically required to contain at least one \code{await} statement in 
all possible paths~\cite{ceu.sensys13,esterel.primer}.
%
\CEU shares the same limitations with Esterel and synchronous languages in 
general:
computations that run in unbounded time (e.g., cryptography, image processing) 
do not fit the zero-delay hypothesis, and cannot be directly implemented.

% TODO: par/or vs abort, strong/weak abortion

\subsection{ Unique and Queue-Based External Events }
\label{sec.ceu.exts}

Esterel defines a logical unit of time as a discrete sequence of instants or 
``ticks''.
At each tick, depending on external stimuli the environment provides, an 
arbitrary number of input events can be active simultaneously (including zero).
The set of input events awakes the program, which must react within the current 
tick, in bounded time.

In \CEU, each unique external stimulus itself defines a unit of time.
The execution model for \CEU programs is as follows~\cite{ceu.sensys13}:
%
\begin{enumerate}
\item The program initiates the ``boot reaction'' in a single trail (but 
      parallel constructs may create new trails).
\item Active trails execute until they await or terminate.
      This step is named a \emph{reaction chain}, and always runs in bounded 
      time.
\item The program goes idle and the environment takes control.
\item On the occurrence of a new external input event, the environment awakes 
      \emph{all} trails awaiting that event.
      It then goes to step 2.
\end{enumerate}
%
A program must react completely to an occurring event completely before 
handling the next.
%
Based on the synchronous hypothesis, a program takes no time on step 2 and is 
always idle on step 3.
In practice, if a new external input event occurs while a reaction chain is 
running (step 2), it is enqueued to run in the next reaction.

\begin{figure}[!htb]
\centering
\includegraphics[width=\columnwidth]{tick}
\caption{The discrete notions of time in Esterel and \CEU.
\label{fig.ticks}
}
\end{figure}

Figure~\ref{fig.ticks} compares the discrete notions of time in Esterel and 
\CEU.
The box \code{Real World} shows event occurrences over a continuous timeline 
divided in units of 10 milliseconds.
Since Esterel and \CEU define discrete logical units of time, we describe how 
the events (which are the same in all boxes) fit into their timelines.

\code{Box-1} uses fixed-length ticks in Esterel, within which reactions to 
occurring inputs have to fit~\cite{esterel.fixed} .
%
Here, we assume a \code{R(boot)} reaction which happens before any input at 
\code{tick-0}.
%
The input \code{A} ``physically'' occurs during the boot reaction but, because 
time is logical and discrete, the event is delayed to the next tick.
%
Note that the reaction \code{R(A)} takes more time than \code{tick-1}, causing 
a \emph{timing violation} in the program execution (after the end of 
\code{tick-1} and before the end of \code{R(A)}).
%
The events \code{B} and \code{C} occur during \code{tick-1} and are delayed to 
happen \emph{simultaneously} at \code{tick-2} with \code{R(B+C)}.
%
Since no new events occurred during \code{tick-2}, the CPU stays idle during 
the whole \code{tick-3}.
%
Finally, one instance of event \code{D} and two instances of event \code{E} 
occur ``simultaneously'' during the idle \code{tick-3}.
However, because the program cannot detect both occurrences of \code{E}, only 
one is considered in \code{R(D+E)}.

\code{Box-2} is an alternative that allows variable-length ticks in Esterel 
that adjust to the time the corresponding reaction takes to 
complete~\cite{esterel.variable}.
This approach avoids the time violation for \code{R(A)} and also yields
smaller idle periods.
For instance, the occurrence of \code{D} interrupts the idle \code{tick-3} to 
start reaction \code{R(D)} on \code{tick-4}.
Similarly to the fixed-tick approach, only one of the two simultaneous 
occurrences of \code{E} is considered on \code{tick-5}.

\code{Box-3} illustrates the unique and queue-based policy for input events in 
\CEU.
We also assume a \code{R(boot)} reaction before any input.
%
Because the event \code{A} is unique during \code{tick-0}, the behavior in \CEU 
is similar to \code{Box-2} for the first two units of time.
%
However, the events \code{B} and \code{C} are not simultaneous in \CEU and are 
handled in subsequent reactions \code{R(B)} and \code{R(C)}.
%
We assume that the CPU time for \code{R(B+C)} in Esterel is roughly the same as 
\code{R(B)+R(C)} in \CEU.
This way, the first idle period in \code{Box-2} and \code{Box-3} coincide.
%
Finally, \CEU recognizes and reacts to the two instances of \code{E} 
independently, which are handled in sequence.

We decided for the unique and queue-based semantics for the reasons that 
follow:
%
\begin{itemize}
\item \textbf{A ``tick'' is too abstract and imprecise:}
Outside the domain of hardware specification, a tick has no natural counterpart 
in the real world.
Also, since no time regularity is required for ticks~\cite{esterel.multiclock}, 
the two approaches for Esterel in Figure~\ref{fig.ticks} lead to different 
behaviors for the same sequence of inputs.
%
\item \textbf{Events are never simultaneous:}
From a rigorous point of view, event occurrences are infinitesimal, having zero 
probability of being simultaneous.
This way, we believe that the notion of simultaneity should not be imposed by 
the language, but explicitly defined for each use case.
In the end of the section, we present a specification to detect 
``simultaneous'' button clicks.
%
Note that in the case of Esterel, simultaneity depends on the imprecise 
definition of ticks.
For instance, in Figure~\ref{fig.ticks}, the events \code{B} and \code{C} are
simultaneous, even though \code{A} and \code{B} actually happen much closer to 
one another.
\item \textbf{Unique input events imply mutual exclusion:}
Because they are atomic, reactions to different events never overlap.
The possibility to reason about each input individually is a prerequisite for 
the temporal analysis to be discussed in Section~\ref{sec.ceu.analysis}.
\end{itemize}

\begin{figure}
\begin{minipage}[t]{0.57\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3em,mathescape=true]
input void LEFT_CLICK;
input void RIGHT_CLICK;
event void middle_click;
loop do
    par/or do
        AWAIT_AND(LEFT_CLICK, RIGHT_CLICK);
        emit middle_click;
    with
        AWAIT_OR(LEFT_CLICK, RIGHT_CLICK);
        await 200 ms;
    end
end
\end{lstlisting}
\end{minipage}
%
\begin{minipage}[t]{0.43\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3em,firstnumber=13]
#define AWAIT_AND(e1, e2)   \
    par/and do              \
        await e1;           \
    with                    \
        await e2;           \
    end
#define AWAIT_OR(e1, e2)    \
    par/or do               \
        await e1;           \
    with                    \
        await e2;           \
    end
\end{lstlisting}
\end{minipage}
%\rule{8.4cm}{0.37pt}
\caption{ Application defines that a \code{middle\_click} event occurs whenever 
both \code{LEFT\_CLICK} and \code{RIGHT\_CLICK} occur within 200 milliseconds.
\label{lst.simultaneous}
}
\end{figure}

Figure~\ref{lst.simultaneous} emulates a \code{milddle\_click} event (ln. 3) in 
terms of \code{LEFT\_CLICK} and \code{RIGHT\_CLICK} (ln. 1--2).
If both events occur, we emit the internal event \code{middle\_click} (ln.  
6--7).
However, if one of them occurs and the \emph{200ms} timer expires (ln. 9--10), 
we abort the whole behavior with the \code{par/or} (ln. 5--11) and try again 
with the enclosing \code{loop} (ln. 4).
The macros \code{AWAIT\_AND} (ln. 13--18) and \code{AWAIT\_OR} (ln. 19--24) are 
simple expansions to a \code{par/and} and \code{par/or} for better readability.
%
Here, ``simultaneous'' means ``within 200 milliseconds'', which is a huge 
amount of time for a language-defined tick, and which would break the 
synchronous hypothesis.
%
A similar implementation for Esterel would not rely on the tick notion of 
simultaneity either.
%
We discuss internal events in Section~\ref{sec.ceu.ints} and timers in 
Section~\ref{sec.ceu.timers}.

The synchronous hypothesis for \CEU holds if the reactions run faster than the 
rate of incoming input events.
Otherwise, the system will accumulate delays between the real occurrence and 
actual reaction to events.
%
This is also the case for the variable-length-tick approach of Esterel, since 
the more inputs to handle, the longer the reaction takes, and the more inputs 
will accumulate for subsequent ticks.
%
For the fixed-length-tick approach of Esterel, a breach in the synchronous 
hypothesis causes timing violations, which can be avoided with \emph{worst case 
reaction time} analysis to infer an appropriate value for the tick 
length~\cite{esterel.fixed}.

\begin{comment}
> Multiclock Esterel
The Esterel synchronous reactive language [5,4,6], which we call Classic Esterel
in this paper, is based on a single-clock instantaneous interaction principle. The
behavior of a program is defined by a sequence of reactions to input sequences.
The execution environment decides when the program is provided an input, and
a reaction is viewed as the simultaneous production of an output response to
an input event. We call ticks the instants in which reactions occur, and master
clock the sequence of these instants (it is a logical clock and no time regularity
is required).

An Esterel Processor with Full Preemption Support and its Worst Case Reaction 
Time Analysis
3. ESTEREL AND THE KIEL ESTEREL PROCESSOR
The execution of an Esterel program is divided into (logical) instants, or 
(logical) ticks, which are conceptually executed infinitely fast.
An Esterel program interacts with its environment through signals, which are 
either present throughout a logical instant or absent.
Input signals are sampled at each tick, and each tick may generate output 
signals.
It would be possible to have the system just compute one logical instant after 
the other, to start with the next reaction as soon as the previous one has 
finished; however, typically the ticks are executed at some fixed frequency, 
resulting in an interval T between each tick, where T is determined by the 
real-time requirements of the system.
The conceptually infinitely fast computation of the reaction within a logical 
tick, plus in the case of Esterel the unique signal presence/absence status 
throughout a logical tick, together constitute the synchrony hypothesis. In 
practice, the results of a logical instant of course cannot be computed 
infinitely fast; however, to maintain the abstraction of the synchrony 
hypothesis, a logical instant must be computed within some desired reaction 
time T.

4. WORST CASE REACTION TIME ANALYSIS
TODO: requires this, what about this in the context of MThreads??
Towards Direct Execution of Esterel Programs on Reactive Processors
3.1 Preserving the Synchrony Hypothesis
The synchronous model implies that reactions to input signals are instantaneous 
and occur at discrete logical instants called ticks.
As a result, a sequence of actions may need to be performed within the duration 
of a single tick.
In order to model the logical tick of Esterel in RePIC, a tick with variable 
length in terms of absolute time is implemented.
The duration of one tick is determined by the time required to execute all the 
instantaneous instructions that are placed between any two consecutive await 
(i.e. TAWAIT, SAWAIT or CAWAIT) or halt instructions which are the tick 
delimiting instructions.
(TODO: tem figuras)
\end{comment}

\subsection{ Stack-Based Internal Events }
\label{sec.ceu.ints}

Esterel makes no semantic distinctions between internal and external signals.
In particular, programs can emit different external input signals 
simultaneously, with all coexisting during a reaction.
%
In \CEU, a reaction starts from an external input event and programs cannot 
emit inputs at all.
Therefore, the occurring input event is unique during the entire reaction, 
resulting in intrinsic queue-based handling.
%
In contrast, programs can emit internal events but these follow a stack-based 
execution policy, similar to subroutine calls in typical programming languages.
%
Figure~\ref{lst.prints} illustrates the use of internal signals (events) in 
Esterel (a) and \CEU (b).
%
In Esterel, when \code{A} occurs, \code{B} is emitted (ln. 4--5) and both 
events become active, resulting in the invocation of \code{f()} and \code{g()} 
in no particular order.
%
In \CEU, the occurrence of \code{A} makes the program behave as follows:
%
{\small
\begin{enumerate}
\setlength{\itemsep}{0pt}
\item 1st trail awakes (ln. 4), emits \code{b}, and pauses.
\item 2nd trail awakes (ln. 8), calls \code{\_g()}, and terminates.
\item 1st trail (on top of the stack) resumes, calls \code{\_f()}, and 
    terminates.
\item Both trails have terminated, so the \code{par/and} rejoins, and the 
program also terminates.
\end{enumerate}
}

\begin{figure}
\begin{minipage}[t]{0.43\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3.5em,mathescape=true]
input A;    // external
signal B;   // internal
[[
    await A;
    emit B;
    call f();
$\|$
    await B;
    call g();
]]
\end{lstlisting}
\centering\small{(a) Esterel}
\end{minipage}
%
\begin{minipage}[t]{0.53\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3.1em]
input void A;  // external (in uppercase)
event void b;  // internal (in lowercase)
par/and do
    await A;
    emit b;
    _f();
with
    await b;
    _g();
end
\end{lstlisting}
\centering\small{(b) \CEU}
\end{minipage}
%\rule{8.4cm}{0.37pt}
\caption{ Internal signals (events) in Esterel and \CEU: similar syntax, but 
different semantics.
\label{lst.prints}
}
\end{figure}

Internal events provide a fine-grained intra-reaction control mechanism.
For instance, it brings a limited form of subroutines, as depicted in 
Figure~\ref{lst.sub}.
The subroutine \code{inc} is defined as a loop (ln. 3--6) that continuously 
awaits its identifying event (ln. 4), incrementing the value passed as 
reference (ln. 5).
A trail in parallel (ln. 8--11) invokes the subroutine in reaction to event 
\code{A} through an \code{emit} (ln. 10).
Given the stacked execution for internal events, the calling trail pauses, the 
subroutine awakes (ln. 4), runs its body (yielding \code{v=2}), loops, and 
awaits the next ``call'' (ln. 4, again).
Only after this sequence the calling trail resumes and passes the assertion 
test (ln. 11).
 
\begin{figure}
\begin{lstlisting}[numbers=left,xleftmargin=2em]
event int* inc; // subroutine `inc'
par/or do
    loop do     // definitions are loops
        var int* p = await inc;
        *p = *p + 1;
    end
with
    var int v = 1;
    await A;
    emit inc => &v; // call `inc'
    _assert(v==2);  // after return
end
\end{lstlisting}
\caption{ Subroutine \code{inc} is defined in a loop (ln. 3--6), in parallel 
with the caller (ln. 8--11).
\label{lst.sub}
}
\end{figure}

% TODO: .. will probably expect that duplicating the  emit inc => &v; line 
% would result in v==3.

On the one hand, this form of subroutines has a significant limitation that it 
cannot express recursive calls: an \code{emit} to itself is always ignored, 
given that a running body cannot be awaiting itself.
%
On the other hand, this very same limitation brings some important safety 
properties to subroutines:
first, they are guaranteed to react in bounded time;
second, memory for locals is also bounded, not requiring data stacks.
%
Also, this form of subroutines can use the other primitives of \CEU, such as 
parallel compositions and the \code{await} statement.
In particular, they await keeping context information such as locals and the 
program counter, similarly to coroutines~\cite{lua.coroutines}.
%In Section~\ref{sec.adv.excpt} we show how to use them to implement 
%exceptions.

Another distinction regarding event handling in comparison to \CEU is that 
Esterel supports same-cycle bi-directional 
communication~\cite{esterel.compiling}, i.e., two threads can react to one 
another during the same cycle due to mutual signal dependency.
%
\CEU has a different take, posing a tradeoff that an \code{await} is only valid 
for the next reaction, i.e., if an \code{await} and \code{emit} occur 
simultaneously in parallel trails, the \code{await} does not awake.
%
These \emph{delayed awaits} avoid corner cases of instantaneous termination and 
re-execution of statements in the same reaction (known as \emph{schizophrenic 
statements}~\cite{esterel.constructive}).

The example in Figure~\ref{lst.await} illustrates delayed awaits, which 
prevents infinite execution by design.
Both sides of the \code{par/or} have an \code{await} statement to avoid 
instantaneous termination (ln. 4,7).
However, if the \code{emit} (ln. 6) could awake the \code{await} (ln. 4) in the 
same reaction that reaches them, the \code{par/or} would terminate and restart 
the \code{loop} instantaneously, resulting in infinite execution.

\begin{figure}
\begin{lstlisting}[numbers=left,xleftmargin=2em]
event void e,f;
loop do
    par/or do
        await e;
    with
        emit e;     // w/o delayed awaits, the emit awakes 1st trail
        await f;    // and restarts the loop instantaneously
    end
end
\end{lstlisting}
\caption{ Delayed awaits prevents re-execution of statements by design.
\label{lst.await}
}
\end{figure}

In atypical scenarios requiring immediate awake, delayed awaits can be 
circumvented by manually copying or transforming the code to execute on awake.
%
For instance, sometimes we need to execute a block of code immediately, and 
then, periodically from internal event requests, as illustrated in 
Figure~\ref{lst.delay}.
In this case, the \code{await} moved to the end of the loop (ln. 10) makes the 
periodic code to also execute immediately (ln. 9), and then in reactions to 
each \code{emit} request (ln. 5).
If the periodic \code{emit} depends on a condition, then the code 
transformation becomes more intricate, requiring an extra condition test around 
the periodic code to prevent its immediate execution.
%
On the one hand, we transfer the burden of dealing with these specific corner 
cases to the programmer.
On the other hand, we simplify the semantics of the language and eliminate the 
need for complex analysis to deal with schizophrenic statements.

\begin{figure}[t]
%\begin{minipage}[t]{0.50\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3em]
event void e;
par do
    loop do
        <...>     // code that awaits some period
        emit e;   // periodic request
    end
with
    loop do
        <...>     // code to execute immediately and then periodically
        await e;  // await after
    end
end
\end{lstlisting}
%\end{minipage}
%
%\begin{minipage}[t]{0.50\linewidth}
%\begin{lstlisting}[numbers=left,xleftmargin=3em]
%event void e;
%var bool should_execute = false;
%par do
%    loop do
%        <...>         // code that awaits
%        if <...> then // some conditon
%            should_execute = true;
%            emit e;
%        end
%    end
%with
%    loop do
%        if should_execute then
%            <...>     // code to execute
%        end
%        await e;
%    end
%end
%\end{lstlisting}
%\end{minipage}
%
\caption{ An example that circumvents the \emph{delayed await} by post-fixing 
the \code{await} inside the \code{loop}.
% (in the left), and by copying the condition test (in the right).
\label{lst.delay}
}
\end{figure}

%\newpage %TTT

\subsection{ Static Temporal Analysis for Concurrent Statements }
\label{sec.ceu.analysis}

Embedded applications make extensive use of global memory and shared resources, 
such as through memory-mapped registers and system calls to device drivers.
Hence, an important goal of \CEU is to ensure a reliable behavior for programs 
with concurrent lines of execution sharing memory and interacting with the 
environment.

Esterel is only deterministic with respect to reactive control: ``the same 
sequence of inputs always produces the same sequence of 
outputs''~\cite{esterel.primer}.
%
However, the execution order for operations within a reaction is 
non-deterministic: ``if there is no control dependency, as in \code{<<call f1() 
|| call f2()>>}, the order is unspecified and it would be an error to rely on 
it''~\cite{esterel.primer}.
%
A number of Esterel-based synchronous languages, such as 
\emph{SOL}~\cite{wsn.sol},
\emph{SC}~\cite{rp.sychc}, and
\emph{PRET-C}~\cite{rp.pretc},
enforce intra-reaction determinism with an arbitrary execution order for 
statements in multiple lines of execution.
%, e.g., based on lexical order or manual priority assignment.
%
\CEU also takes the deterministic approach and when multiple trails are active 
during the same reaction, they are scheduled in the order they appear in the 
program source code.

\begin{figure}
\begin{minipage}[t]{0.50\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3em]
input void A, B;
var int x = 1;
par/and do
    await A;
    x = x + 1;
with
    await B;
    x = x * 2;
end
\end{lstlisting}
\centering\small{(a)}
\end{minipage}
%
\begin{minipage}[t]{0.50\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3em]
input void A;
var int y = 1;
par/and do
    await A;
    y = y + 1;
with
    await A;
    y = y * 2;
end
\end{lstlisting}
\centering\small{(b)}
\end{minipage}
%\rule{8.4cm}{0.37pt}
\caption{ Shared-memory concurrency in \CEU:
Example (a) is safe because the trails access \code{x} atomically in different 
reactions;
Example (b) is unsafe because both trails access \code{y} in the same reaction.
\label{lst.shared}
}
\end{figure}

Even so, we consider that enforcing an arbitrary execution order can be 
misleading in some cases.
%
For instance, consider the two examples in Figure~\ref{lst.shared}, both of 
which define a shared variable (ln. 2), and assign to it parallel trails (ln.  
5, 8).
%
In the example \code{(a)}, the two assignments to \code{x} execute from 
reactions to different events \code{A} and \code{B} which, by definition, 
cannot occur simultaneously (Section~\ref{sec.ceu.exts}).
Hence, for the sequence \code{A->B}, \code{x} becomes \code{(1+1)*2->4}, while 
for \code{B->A}, \code{x} becomes \code{(1*2)+1->3}.
%
In the example \code{(b)}, the two assignments to \code{y} execute from a 
reaction to the same event \code{A}, and are simultaneous from an external 
point of view.
Since \CEU employs lexical order for intra-reaction statements, the execution 
is still deterministic, and \code{y} always becomes \code{(1+1)*2->4}.
%
However, any (apparently innocuous) change in the order of trails can change 
the semantics of a program, which we consider unsafe.

To mitigate this threat, \CEU performs a temporal analysis at compile time and 
detects concurrent accesses to shared variables, as follows:
if a variable is written in a trail segment, then a concurrent trail segment 
cannot read or write to that variable, nor dereference a pointer of that 
variable type.
%An analogous policy is applied for pointers \emph{vs} variables and pointers 
%\emph{vs} pointers.
%
A trail segment is a sequence of statements followed by an \code{await} (or 
termination).
Concurrency in \CEU is characterized when two or more trail segments in 
parallel react to the same input event.
%
Considering the examples in Figure~\ref{lst.shared}:
%
\begin{itemize}
\item The assignments to \code{x} in lines 2 and 5 in \code{(a)}
      \textbf{cannot} be concurrent because they are not in parallel trails.
\item The assignments to \code{x} in lines 5 and 8 in \code{(a)}
      \textbf{cannot} be concurrent because they \textbf{cannot} execute during 
      the same reaction.
\item The assignments to \code{y} in lines 5 and 8 in \code{(b)}
      \textbf{can} be concurrent because they are in parallel trails and 
      \textbf{can} execute during the same reaction.
\end{itemize}
%
The algorithm for the analysis, which is depicted in 
Section~\ref{sec.impl.analsyis}, inspects all possible \code{await} statements 
that precede a variable access and hold the associated awaking events.
Then, it checks all accesses in parallel trails to see if they share an awaking 
event.
If it is the case, the compiler warns about the suspicious accesses.

Note that this analysis is only possible due to the uniqueness of input events 
within reactions.
Otherwise, any two trail segments in parallel could be concurrent, even if they 
react to different input events.

\subsection{ Safe Integration with \C }
\label{sec.ceu.c}

In \CEU, any identifier prefixed with an underscore is repassed \emph{as is} to 
the \C compiler that generates the final binary.
Therefore, access to \C is seamless and, more importantly, easily trackable.
%
Similarly to Esterel, which supports the \code{call} primitive for external 
code, calls are assumed to be instantaneous~\cite{esterel.primer}.
%
Evidently, programs should only resort to \C for asynchronous functionality, 
such as non-blocking I/O, or simple \code{struct} accessors, but never for 
control purposes.

\begin{figure}[b]
\begin{minipage}[t]{0.50\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3.5em]
native do
    #define NUM 10
    void f  (void)  { <...> }
    void g  (int v) { <...> }
    int  id (int v) { <...> }
end
par/and do
    _f();
with
    _g(_id(_NUM));
end
\end{lstlisting}
\centering\small{(a)}
\end{minipage}
%
\begin{minipage}[t]{0.44\linewidth}
\begin{lstlisting}
native @const _NUM;
native @pure  _id;
native @safe  _f with _g;







.
\end{lstlisting}
\centering\small{(b)}
\end{minipage}
%\rule{8.4cm}{0.37pt}
\caption{ TODO
\label{lst.c}
}
\end{figure}

In addition, \CEU also employs the temporal analysis for calls and accesses to 
external symbols in \C.
%
As an example, the program in Figure~\ref{lst.c}.a defines four external 
symbols inside a \code{native} block for standard declarations in \C (ln.  
1--6).
%
The \code{par/and} (ln. 7--11) creates two trails that react concurrently 
during the boot reaction (ln. 8,10):
the first trail calls the symbol \code{\_f},
while the second calls \code{\_g} and \code{\_id}, and also accesses 
\code{\_NUM}.
%
Since \CEU does not inspect any code defined in \C, it has no idea about the 
meaning of the symbols and complains about suspicious concurrent accesses 
between \code{\_f} against all symbols in the second trail.

The code in Figure~\ref{lst.c}.b uses annotations to provide hints to the 
compiler about the semantics of the \C symbols in use in \code{(a)}:
%
\begin{itemize}
\item \code{\_NUM} is a constant symbol, meaning that it is safe to use it 
      concurrently with any other symbol in the program.
\item \code{\_id} is a pure function, also meaning that it is safe to call it
      concurrently with any other symbol in the program.
\item Both \code{\_f} and \code{\_g} are impure, but their effects do not 
      conflict and they can be safely called concurrently.
\end{itemize}

Esterel's \code{abort} and \CEU's \code{par/or} statements illustrate how 
synchronous languages can abort awaiting lines of execution without tweaking 
them with synchronization primitives.
In contrast, traditional (asynchronous) multi-threaded languages cannot express 
thread termination safely~\cite{esterel.preemption,sync_async.threadsstop}.
%
Still, aborting lines of execution that deal with external resources is 
challenging because they may end up in an inconsistent state.
%
For this reason, Esterel and \CEU provide a \code{finalize} construct with a 
clause that executes even if the enclosing block aborts and does not terminate 
normally.

Figure~\ref{lst.fin} uses \code{lock} and \code{unlock} calls to represent an 
external resource.
The normal behavior is to \code{lock} the resource, perform some operations in 
subsequent reactions to input \code{A}, and then \code{unlock} the resource.
However, if the aborting input \code{B} occurs after the \code{lock} but before 
the reactions to \code{A}, we still want to call \code{unlock} to safely 
release the resource.
%
In Esterel and \CEU, the finalize clauses (ln. a:10 and b:5) are automatically 
called if the enclosing blocks (ln. a:3--1 and b:3--10) are externally aborted 
(ln. a:12 and b:12).

\begin{figure}
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3.5em,mathescape=true]
input A, B;
abort
    finalize
        call lock();
        await A;
        <...>;      // do something
        await A;
        <...>;      // do something
    with
        call unlock();
    end
when B
.
\end{lstlisting}
\centering\small{(a) Esterel}
\end{minipage}
%
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3.5em]
input void A, B;
par/or do
    _lock();
    finalize with
        _unlock();
    end
    await A;
    <...>;      // do something
    await A;
    <...>;      // do something
with
    await B;
end
\end{lstlisting}
\centering\small{(b) \CEU}
\end{minipage}
%\rule{8.4cm}{0.37pt}
\caption{
Finalization in Esterel and \CEU: after the call to \code{lock}, both languages 
guarantee to call \code{unlock} if the enclosing block aborts when \code{B} 
occurs.
\label{lst.fin}
}
\end{figure}

\CEU goes one step further and enforces the use of \code{finalize} for system 
calls that deal with pointers representing resources:
%
\begin{itemize}
\item If a system call \textbf{receives} a pointer from \CEU, the pointer 
represents a \textbf{local} resource that requires finalization.
\item If a system call \textbf{returns} a pointer to \CEU, the pointer 
represents an \textbf{external} resource that requires finalization.
\end{itemize}
%
\CEU tracks the interaction of system calls with pointers and requires 
finalization clauses to accompany them.
%
In the example in Figure~\ref{lst.fin.ceu}.a, the local variable \code{msg} 
(ln. 2) is an internal resource passed as a pointer to \code{\_send\_request} 
(ln. 5), which is an asynchronous call that transmits the buffer in the 
background.
If the block aborts (ln. 11) before receiving an acknowledge from the 
environment (ln. 9), the local \code{msg} goes out of scope and the external 
transmission now holds a \emph{dangling pointer}.
The finalization ensures that the transmission also aborts (ln. 7).
%
In the example in Figure~\ref{lst.fin.ceu}.b, the call to \code{\_fopen} 
returns an external file resource as a pointer.
If the block aborts (ln. 12) during the \code{await A} (ln. 9), the file 
remains open as a \emph{memory leak}.
The finalization ensures that the file closes properly (ln. 6).
%
In both cases, the code does not compile if the programmer forgets to use the
\code{finalize} construct.

Note that the illustrative example of Figure~\ref{lst.fin} does not manipulate 
pointers (i.e., the resource is a \emph{singleton}).
That case is an example of a bad and unsafe API to expose to \CEU because the 
compiler will not enforce the use of finalization.
%
%TODO: @nohold
%Note also that \CEU environments rely on \C libraries that only provide 
%asynchronous I/O and non-blocking functions~\cite{ceu.sensys13}.

\begin{figure}
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3.5em,mathescape=true]
par/or do
   var _buffer_t msg;
   <...> // prepare msg
   finalize
      _send_request(&msg);
   with
      _send_cancel(&msg);
   end
   await SEND_ACK;
with
   <...>
end
.
\end{lstlisting}
\centering\small{(a) Local resource finalization}
\end{minipage}
%
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3.5em]
par/or do
   var _FILE* f;
   finalize
      f = _fopen(...);
   with
      _fclose(f);
   end
   _fwrite(..., f);
   await A;
   _fwrite(..., f);
with
   <...>
end
\end{lstlisting}
\centering\small{(b) External resource finalization}
\end{minipage}
%\rule{8.4cm}{0.37pt}
\caption{
\CEU enforces the use of finalization to prevent \emph{dangling pointers} for 
local resources and \emph{memory leaks} for external resources.
\label{lst.fin.ceu}
}
\end{figure}

\subsection{ First-Class Timers }
\label{sec.ceu.timers}

Activities that involve reactions to \emph{wall-clock time}%
\footnote{
By wall-clock time we mean the passage of time from the real world, measured in 
hours, minutes, etc.
}
appear in typical patterns of embedded development, such as timeout watchdogs 
and sensor samplings.
However, support for wall-clock time is somewhat low-level in existing 
languages, usually through timer callbacks or ``sleep'' blocking calls.
%
Furthermore, in any concrete timer implementation, a requested timeout does not 
expire precisely without delays, a fact that is usually ignored in the 
development process.
We define the difference between the requested timeout and the actual expiring 
time as the \emph{residual delta time (delta)}.
Without explicit manipulation, the recurrent use of timed activities in 
sequence (or in a loop) may accumulate a considerable amount of deltas that can 
lead to incorrect behavior in programs.

The \code{await} statement of \CEU supports wall-clock time and handles deltas 
automatically, resulting in more robust applications.
For the example in Figure~\ref{lst.timers}.a, suppose that after the first 
\code{await} request, the underlying system gets busy and takes 15ms to check 
for expiring awaits.
The \CEU scheduler will notice that the \code{await 10ms} has not only already 
expired, but is delayed with \code{delta=5ms}.
Then, the awaiting trail awakes, sets \code{v=1}, and invokes \code{await 1ms}.
As the current delta is higher than the requested timeout (i.e. $5ms > 1ms$), 
the trail is rescheduled for execution, now with \code{delta=4ms}.

\begin{figure}
\begin{minipage}[t]{0.45\linewidth}
\begin{lstlisting}
var int v;
await 10ms;
v = 1;
await 1ms;
v = 2;



.
\end{lstlisting}
\centering\small{(a)}
\end{minipage}
%
\begin{minipage}[t]{0.51\linewidth}
\begin{lstlisting}
par/or do
    await 10ms;
    <...>         // any non-awaiting sequence
    await  1ms;
    v = 1;
with
    await 12ms;
    v = 2;
end
\end{lstlisting}
\centering\small{(b)}
\end{minipage}
%\rule{8.5cm}{0.37pt}
\caption{ First-class timers in \CEU.
\label{lst.timers}
}
\end{figure}

\CEU also takes into account the fact that time is a physical quantity that can 
be added and compared.
For instance, for the example in Figure~\ref{lst.timers}.b, although the 
scheduler cannot guarantee that the first trail terminates exactly in 11ms, it 
can at least ensure that the program always terminates with \code{v=1}.
%
Given that any non-awaiting sequence is considered to take no time in the 
synchronous model, the first trail is guaranteed to terminate before the second 
trail, because $10+1 < 12$.
%
A similar program in a language without first-class support for timers would 
depend on the execution timings for the code marked as \code{<...>}, making the 
reasoning about the execution behavior more difficult.

\subsection{ Discussion }
\label{sec.ceu.dicsussion}

TODO add a remark about tasks/async/thread in "Discussion"

TODO Link the sections, connect the dots, draw conclusions, eliminate remaining xxx.

Timers allows for an internal, defined by the programmer in charge of the 
specification, definition of simultaneity.

On the one hand, enforcing an execution order for concurrent operations may 
seen arbitrary and also precludes true parallelism.
On the other hand, it provides a priority scheme for trails, and makes 
shared-memory concurrency more tractable.
%
For constrained embedded development, we believe that deterministic 
shared-memory concurrency is beneficial, given the extensive use of memory 
mapped ports for \emph{I/O} and the lack of hardware support for real 
parallelism.

TODO: we could detect that trails do not share memory and execute in multiple 
threads

%For Esterel, however, is also used in hardware design~\cite{rp.twelve} where 
%parallelism is inherent.


\section{Implementation}
\label{sec.impl}

The compilation process of a program in \CEU for the original \C back end is 
composed of three main phases:
the \emph{parsing phase} converts the source code in \CEU to an \emph{abstract 
syntax tree (AST)};
the \emph{temporal analysis phase} detects inconsistencies in programs, such as 
unbounded loops and suspicious accesses to shared memory;
the \emph{code generation phase} converts the \emph{AST} to standard \C code 
and packs it with platform-dependent functionality (e.g., system calls) and the 
runtime of \CEU, compiling everything with \emph{gcc} to generate the final 
binary.

In the sections that follow, we discuss the implementation highlights related 
to the peculiarities of \CEU:
the temporal analysis for determinism (Section~\ref{sec.impl.analysis}),
static memory allocation for data and trails (Sections~\ref{sec.impl.data} 
and~\ref{sec.impl.trails}),
static scheduling and trail finalization (Section~\ref{sec.impl.scheduler}),
interaction with the environment (Section~\ref{sec.impl.environment}),
and the \VM back end (Section~\ref{sec.terra}),

\subsection{Temporal Analysis for Concurrent Statements}
\label{sec.impl.analysis}

TODO: internal events, emits are propagated from preceding awaits to input

The compile-time \emph{temporal analysis} phase detects inconsistencies in \CEU 
programs.
Here, we focus on the algorithm that detects suspicious access to shared 
variables, as discussed in Section~\ref{sec.ceu.analysis}.

For each node representing a statement in the program AST, we keep the set of 
events $I$ (for \emph{incoming}) that can lead to the execution of the node, 
and also the set of events $O$ (for \emph{outgoing}) that can terminate the 
node.

A node inherits the set $I$ from its direct parent and calculates $O$ according 
to its type:
%
\begin{itemize}
%
\item Nodes that represent expressions, assignments, \C calls, and declarations 
simply reproduce $O=I$, as they do not await;
%
\item An \code{await e} statement has $O=\{e\}$.
%
\item A \code{break} statement has $O=\{\}$ as it escapes the innermost 
\code{loop} and never terminates, i.e., never proceeds to the statement 
immediately following it (see also \code{loop} below);
%
\item A \emph{sequence node (;)} modifies each of its children to have 
$I_n=O_{n-1}$.
The first child inherits $I$ from its parent node, and the set $O$ for the 
sequence node is copied from its last child, i.e., $O=O_n$.
%
\item A \code{loop} node includes its body's $O$ on its own $I$ ($I=I \cup 
O_{body}$), as the loop is also reached from its own body.
The union of all \code{break} statements' $O$ forms the set $O$ for a 
\code{loop}.
%
\item An \code{if} node has $O=O_{true} \cup O_{false}$.
%
\item A parallel composition may terminate from any of its branches, hence $O = 
O_1 \cup ... \cup O_n$.
\end{itemize}

With all sets calculated, we take all pairs of nodes that perform side effects 
and are in parallel branches, comparing their sets $I$ for intersections.
For each pair, if the intersection is not the empty set, we mark both nodes as 
suspicious.

The example in Figure~\ref{lst.impl.ast}.a has a corresponding $AST$, in 
Figure~\ref{lst.impl.ast}.b, with the sets $I$ and $O$ for each node.
The event $.$ (dot) represents the ``boot'' reaction.
The assignments to \code{y} in parallel (ln. 5,8 in the code) have an empty 
intersection of $I$ (ln. 6,9 in the AST), hence, they do not conflict.
Note that although the accesses in ln. 5,11 in the code (ln. 6,11 in the AST) 
do have an intersection, they are not in parallel and are also safe.

\begin{figure}
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=2.5em]
input void A, B;
var int y;
par/or do
  await A;
  y = 1;
with
  await B;
  y = 2;
end
await A;
y = 3;
\end{lstlisting}
\centering\small{(a)}
\end{minipage}
%
%
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=2.5em]
Stmts I={.} O={A}
    Dcl_y I={.} O={.}
    ParOr I={.} O={A,B}
        Stmts I={.} O={A}
            Await_A I={.} O={A}
            Set_y I={A} O={A}
        Stmts I={.} O={B}
            Await_B I={.} O={B}
            Set_y I={B} O={B}
    Await_A I={A,B} O={A}
    Set_y I={A} O={A}
\end{lstlisting}
\centering\small{(b)}
\end{minipage}
%
%\rule{14cm}{0.37pt}
\caption{ A program with a corresponding AST describing the sets $I$ and $O$.
%{\small %\textmd{
The program is safe because accesses to \code{y} in parallel have no 
intersections for $I$.
%}%}
\label{lst.impl.ast}
}
\end{figure}

\begin{comment}
It is also responsible for setting the priorities for trails (see further) and 
determining the sizes of the queues that are used during runtime.

The program AST is first converted into a graph that represents the execution 
flow.
Figure~\ref{fig:nfa} shows the corresponding graph for our example.

\begin{figure}
\centering
\includegraphics[scale=0.40]{nfa.png}
\caption{ Flow graph for our guiding example
\label{fig:nfa}
}
\end{figure}

By default, all nodes in a flow graph have priority $0$ (highest).
However, as the figure shows, nodes that represent the termination of 
\emph{par/ors} and loops have lower priorities (the outer, the lower).
The priority scheme is needed to avoid glitches during runtime, and is 
equivalent to traversing a dependency graph in topological order, as employed 
in functional reactive programming implementations.~\cite{frtime.embedding}

The flow graph is then converted to a DFA, as exemplified in 
Section~\ref{sec:ceu:det}.

From its starting node, the flow graph is traversed until reaching await 
nodes---every visited node is inserted into a new DFA state.
Then, every set of awaiting nodes for a given external event starts another DFA 
state.
\end{comment}

\subsection{Static Memory Layout}
\label{sec.impl.data}

\CEU favors a fine-grained use of trails, being common to use trails that await 
a single event.
For this reason, \CEU does not allocate per-trail stacks; instead, all data 
resides in fixed memory slots---this is true for the program variables as well 
as for temporary values and runtime flags.
%For instance, the first trail in the guiding example requires temporary slots 
%to hold the locals \code{a} and \code{b}, while the second trail must keep 
%flags to remember which sides of the \code{par/and} have already terminated.
%
Memory for trails in parallel must coexist, while statements in sequence can 
reuse it.
%
Translating this idea to \C is straightforward~\cite{wsn.osm,wsn.ocram}: memory 
for blocks in sequence are packed in a \code{struct}, while blocks in parallel, 
in a \code{union}.
%In the example, the code following the loop (identified as \code{...}) reuses 
%all memory from the loop.
%
\CEU reserves a single static block of memory to hold all memory slots, whose 
size is the maximum the program uses at a given time.
A given position in the memory may hold different data (with variable sizes) 
during runtime.
%
As an example, Figure~\ref{lst.impl.mem} shows a program with corresponding 
memory layout.
%
Each variable is assigned a unique $id$ (e.g. \code{a\_1}) so that variables 
with the same name can be distinguished.
%
The \code{do-end} blocks in sequence are packed in a \code{union}, given that 
their variables cannot be in scope at the same time, e.g., \code{MEM.a\_1} and 
\code{MEM.b\_2} can safely share the same memory slot.
%
The example also illustrates the presence of runtime flags related to the 
parallel composition, which also reside in reusable slots in the static memory.

\begin{figure}
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}
input int A, B, C;
do
    var int a = await A;
end
do
    var int b = await B;
end
par/and do
    await B;
with
    await C;
end
\end{lstlisting}
\end{minipage}
%
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}
union {             // sequence
    int a_1;        //   do_1
    int b_2;        //   do_2
    struct {        //   par/and
        int _and_3: 1;
        int _and_4: 1;
    };
} MEM ;
\end{lstlisting}
\end{minipage}
%\rule{14cm}{0.37pt}
\caption{
A program with blocks in sequence and in parallel, with corresponding memory 
layout generated by the compiler.
{\small %\textmd{
}%}
\label{lst.impl.mem}
}
\end{figure}

\subsection{Static and Lightweight Trail Allocation}
\label{sec.impl.trails}

Each line of execution in \CEU needs to carry associated data, such as which 
event it is awaiting and which code to execute when it awakes.
%
The compiler statically infers the maximum number of trails a program can have 
at the same time and creates a static vector to hold the runtime information 
about them.
%
Like normal variables, trails that cannot be active at the same time can share 
slots in the static memory vector.

At any given moment, a trail can be awaiting in one of the following states: 
\code{INACTIVE}, \code{STACKED}, \code{FINALIZE}, or in any of the events 
defined in the program:

\begin{lstlisting}
enum {
    INACTIVE = 0,
    STACKED,
    FINALIZE,
    EVT_A,      // input void A;
    EVT_e,      // event int e;
    <...>       // other events
}
\end{lstlisting}

All terminated or not-yet-started trails stay in the \code{INACTIVE} state and 
are ignored by the scheduler.
%
A \code{STACKED} trail holds an associated stack level and is delayed until the 
scheduler runtime reaches that level again.
%
A \code{FINALIZE} trail represents a hanged finalization block which is only 
scheduled when its corresponding block goes out of scope.
%
A trail waiting for an event stays in the state of the corresponding event, 
also holding the minimum sequence number (\emph{seqno}) in which it can awake.
%
In concrete terms, a trail is represented by the following \code{struct}:

\begin{lstlisting}
struct trail_t {
    state_t evt;
    label_t lbl;
    union {
        unsigned char seqno;
        stack_t       stk;
    };
};
\end{lstlisting}

The field \code{evt} holds the state of the trail (or the event it is 
awaiting); the field \code{lbl} holds the entry point in the code to execute 
when the trail segment is scheduled; the third field depends on the \code{evt} 
field and may hold the \code{seqno} for an event, or the stack level \code{stk} 
for a
\code{STACKED} state.

The size of \code{state\_t} depends on the number of events in the application;
for an application with less than 253 events (plus the 3 states), one byte is 
enough.
%
The size of \code{label\_t} depends primarily on the number of \code{await} 
statements in the application---each \code{await} splits the code in two 
segments and requires a unique entry point in the code for its continuation.
Additionally, split \& join points for parallel compositions, \code{emit} 
continuations, and finalization blocks also require labels.
%
The \code{seqno} could eventually overflow during execution (i.e., every 256 
reactions).
However, given that the scheduler traverses all trails on every reaction, it 
can adjust them to properly handle overflows (actually, 2 bits to hold the 
\code{seqno} is already enough).
%
The size of \code{stack\_t} depends on the maximum depth of nested emissions 
and is bounded to the maximum number of trails.
In the worst case, a trail emits an event that awakes another trail, which 
emits an event that awakes another trail, and so on.
The last trail cannot awake any trail, because they are all hanged in the 
\code{STACKED} state.

In the context of embedded systems, the size of \code{trail\_t} is typically 
only 3 bytes (1 byte for each field), imposing a negligible memory overhead 
even for trails that only await a single event and terminate.
%
For instance, the \emph{CTP} collection protocol ported to \CEU reaches eight 
simultaneous lines of execution with an overhead of 2\% in comparison to the 
original version in \C~\cite{ceu.sensys13}.

\subsection{Static Scheduling and Trail Finalization}
\label{sec.impl.scheduler}

In the final generated code in \C, each trail segment label representing an 
entry point becomes a \emph{switch case} with the associated code to execute.
%
Figure~\ref{lst.impl.trails} illustrates the generation process.
For the program in (a), the compiler extracts the entry points and associated 
trails, e.g., the label \code{Awake\_e} will execute on \code{TRAIL-0} (ln. 7).
%
For each statement that pauses (\code{emit} and \code{await}), resumes 
(\code{par/and}, \code{par/or}, and \code{finalize}), or aborts (\code{par/or} 
and \code{break}), the compiler splits the trail into segments with associated 
entry points.
%
The entry points translate to an \code{enum} in the generated code (ln. 1--10, 
in (b)).
The state of trails translates to a vector of type \code{trail\_t} with the 
maximum number of simultaneous trails (ln. 12--15).
On initialization, \code{TRAIL-0} is set to execute the \code{Main} entry point 
(ln. 13), while all others are set to \code{INACTIVE} (in the example, only 
one, in ln. 14).

\begin{figure}[t]
\begin{minipage}[t]{0.31\linewidth}
\begin{lstlisting}
input void A;
event void e;
// TRAIL 0 - lbl Main
par/and do
  // TRAIL 0 - lbl Main
  await e;
  // TRAIL 0 - lbl Awake_e
  // TRAIL 0 - lbl And_chk
with
  // TRAIL 1 - lbl And_sub_2
  await A;
  // TRAIL 1 - lbl Awake_A_1
  emit e;
  // TRAIL 1 - lbl Emit_cont
  // TRAIL 1 - lbl And_chk
end
// TRAIL 0 - lbl And_out
await A;
// TRAIL 0 - lbl Awake_A_2





.
\end{lstlisting}
\centering\small{(a)}
\end{minipage}
%
\begin{minipage}[t]{0.31\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=2.5em]
enum {
  Main = 1,  // ln 3
  Awake_e,   // ln 7
  And_chk,   // ln 8,15
  And_sub_2, // ln 10
  Awake_A_1, // ln 12
  Emit_cont, // ln 14
  And_out,   // ln 17
  Awake_A_2  // ln 19
};

trail_t TRLS[2] = {
  { STACKED,  Main, 0 };
  { INACTIVE, 0,    0 };
};









.
\end{lstlisting}
\centering\small{(b)}
\end{minipage}
%
\begin{minipage}[t]{0.37\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=2.5em]
void dispatch (trail_t* t) {
  switch (t->lbl) {
    case Main:
      // activate TRAIL 1
      TRLS[1].evt = STACKED;
      TRLS[1].lbl = And_sub_2;
      TRLS[1].stk = cur_stack;
  
      // code in the 1st trail
      // await e;
      TRLS[0].evt = EVT_e;
      TRLS[0].lbl = Awake_e;
      TRLS[0].seq = cur_seqno;
      break;
  
    case And_sub_2:
      // await A;
      TRLS[1].evt = EVT_A;
      TRLS[1].lbl = Awake_A_1;
      TRLS[1].seq = cur_seqno;
      break;
  
    <...>  // other labels
  }
}
\end{lstlisting}
\centering\small{(c)}
\end{minipage}
\caption{
%{\small %\textmd{
(a) Static allocation of trails: the comments identify the trail indexes 
inferred by the compiler;
(b) Entry-point labels: each trail segment has an associated numeric identifier 
generated by the compiler.
(c) Dispatch function: uses a \code{switch} to associate each segment 
identifier with the corresponding code to execute.
%}%}
\label{lst.impl.trails}
}
\end{figure}

The scheduler executes in two passes:
%
in the \emph{broadcast} pass, it sets all trails that are waiting for the 
current event to \code{STACKED} in the current stack level;
%
in the \emph{dispatch} pass, it executes each trail that is \code{STACKED} to 
run in the current level, setting it immediately to \code{INACTIVE} (the trail 
segment may reset it in sequence if it doesn't terminate).

During the dispatch pass, if a trail executes and emits an internal event, the 
scheduler increments the stack level and re-executes the two passes.
After all trails are properly dispatched, the scheduler decrements the stack 
level and resumes the previous execution.
For the first reaction, the scheduler starts from the \emph{dispatch} pass, 
given that the \code{Main} label is the only one that can be active at the 
stack level 0 (ln. 13, in Figure~\ref{lst.impl.trails}.b).

The code in Figure~\ref{lst.impl.trails}.c dispatches a trail segment according 
to the current label to execute.
%
For the first reaction, it executes the \code{Main} label in \code{TRAIL-0}.
%
When the \code{Main} label reaches the \code{par/and}, it stacks \code{TRAIL-1} 
(ln. 4--7) and proceeds to the code in \code{TRAIL-0} (ln. 9--14), respecting 
the deterministic execution order.
%
The code sets the running \code{TRAIL-0} to await \code{EVT\_e} on label 
\code{Awake\_e}, and then halts with a \code{break}.
%
The next iteration of \code{dispatch} takes \code{TRAIL-1} and executes its 
registered label \code{And\_sub\_2} (ln. 16--21), which sets \code{TRAIL-1} to 
await \code{EVT\_A} and also halts.

Regarding abortion and finalization, when a \code{par/or} terminates, the 
scheduler makes a \emph{broadcast} pass for the \code{FINALIZE} event, but 
limited to the range of trails covered by the terminating \code{par/or}.
Trails that do not match the \code{FINALIZE} are set to \code{INACTIVE}, as 
they have to be aborted.
Given that trails in parallel are allocated in subsequent slots in the static 
vector \code{TRLS}, this pass only aborts the desirable trails.
The subsequent \emph{dispatch} pass executes the finalization code.
%Given that finalization blocks cannot contain \code{await} statements, the 
%whole process is guaranteed to terminate in bounded time.
Escaping a \code{loop} that contains parallel compositions also triggers the 
same abortion process.

\subsection{Single-Threaded Dispatching}

The implementation of \CEU dispatches active trails sequentially in a single 
thread, taking no advantage of multi-core CPUs.
%
This decision comes not only from the fact that \CEU targets constrained 
embedded systems with a single CPU, but also because \CEU imposes deterministic 
execution for intra-reaction statements.

Nonetheless, as discussed in Section~\ref{sec.ceu.analysis}, the temporal 
analysis of \CEU infers precisely trails that are concurrent yet do not share 
resources.
Hence, these non-conflicting trails could potentially execute with real 
parallelism in multiple cores.
%
However, our experiments with a multi-threaded implementation in multi-core 
CPUs execute slower than the single-threaded implementation in the same CPUs.
Considering that we use \CEU primarily in control-dominated applications, this 
result is not surprising~\cite{esterel.multicore.1,esterel.multicore.2}.
We believe that
    the continuous fork-and-rejoin overhead due to small reactions
as well as
    the excessive locality of data due to stackless threads sharing contiguous static memory
seem to prevent any speed-up gains.

If we consider data-dominated applications, multi-core implementations can 
offer considerable speed-up gains.
However, data-intensive computations do not typically require a disciplined 
step-wise execution and can actually execute in asynchronous calls.
Esterel provides a \code{task} primitive for this 
purpose~\cite{esterel.primer}, and \CEU provides an equivalent 
\code{async/thread} primitive (which are out of the scope of this paper).

Since loops in \CEU must contain \code{await} statements, reactions run in 
bounded time, which guarantees that successive calls to \code{dispatch} never 
block the scheduler for long.
However, the code generation phase does not inspect C calls and also has no 
extra analysis such as for worst-case reaction 
times~\cite{esterel.wcrt,esterel.fixed}.

\subsection{Interaction with the Environment}
\label{sec.impl.environment}

As a reactive language, the execution of programs in \CEU is guided entirely by 
the occurrence of external input events.
%
The binding for a specific platform (environment) is responsible for calling 
hook functions in the API of the runtime of \CEU whenever an external event 
occurs.
%
However, the binding must never interleave or run multiple API calls in 
parallel.
This would break the \CEU sequential/discrete semantics of time.

As an example, Figure~\ref{lst.impl.tinyos} shows our binding for 
\emph{TinyOS}~\cite{wsn.tos}, which maps system callbacks to input events in 
\CEU.
%
The file \code{ceu\_app.h} (ln. 3) contains all definitions for the compiled 
\CEU program, which are further queried through \code{\#ifdef}'s.
The file \code{ceu\_app.c} (ln. 4) contains the runtime of \CEU with the 
scheduler and dispatcher pointing to the labels defined in the program.
The callback \code{Boot.booted} (ln. 6--11) is called by TinyOS on startup, so 
we initialize \CEU inside it (ln. 7).
If the \CEU program uses timers, we also start a periodic timer (ln. 8--10) 
that triggers callback \code{Timer.fired} (ln. 13--17) every 10 milliseconds 
and advances the wall-clock time of \CEU (ln. 15)%
\footnote{We also offer a mechanism to start the underlying timer on demand to
avoid the ``battery unfriendly'' 10ms polling.}.
The remaining lines map pre-defined TinyOS events that can be used in \CEU 
programs, such as the light sensor (ln. 19--23) and the radio transceiver (ln.  
25--36).
%
The scheduler of the TinyOS is already synchronous by default and always 
execute \code{event} handlers atomically, hence, the API calls to \CEU are 
properly serialized.

\begin{figure}
\begin{lstlisting}[numbers=left,xleftmargin=2em]
implementation
{
    #include "ceu_app.h"
    #include "ceu_app.c"

    event void Boot.booted () {
        ceu_init();
#ifdef CEU_WCLOCKS
        call Timer.startPeriodic(10);
#endif
    }
    
#ifdef CEU_WCLOCKS
    event void Timer.fired () {
        ceu_wclock(10000);
    }
#endif

#ifdef EVT_PHOTO_READDONE
    event void Photo.readDone (int val) {
        ceu_go(EVT_PHOTO_READDONE, &val);
    }
#endif

#ifdef EVT_RADIO_SENDDONE
    event void RadioSend.sendDone (message_t* msg) {
        ceu_go(EVT_RADIO_SENDDONE, &msg);
    }
#endif

#ifdef EVT_RADIO_RECEIVE
    event message_t* RadioReceive.receive (message_t* msg) {
        ceu_go(EVT_RADIO_RECEIVE, &msg);
        return msg;
    }
#endif

    <...>   // other events
}
\end{lstlisting}
%\rule{14cm}{0.37pt}
\caption{
%{\small %\textmd{
The \emph{TinyOS} binding for \CEU.
This platform-dependent template includes the \C files generated from the 
original application in \CEU (\code{ceu\_app.h} and \code{ceu\_app.c}) for the 
\emph{code generation phase}.
%}%}
\label{lst.impl.tinyos}
}
\end{figure}

\subsection{The Terra Virtual Machine}
\label{sec.terra}

Terra is a system for programming wireless sensor network applications which 
uses \CEU as its scripting language~\cite{ceu.terra}.
%
Figure \ref{fig.terra} shows the three basic elements of Terra:
\CEU as the scripting language,
a set of customized pre-built components,
and the embedded virtual-machine engine which can disseminate and install 
bytecode images dynamically.
%
This approach aims to combine the flexibility of remotely uploading code with 
the expressiveness and safety guarantees of \CEU.

\begin{figure}[!htb]
 \centering
 \includegraphics[width=0.5\columnwidth]{terra}
\caption{Terra programming system basic elements.}
 \label{fig.terra}
\end{figure}

The main difference between the standard \C back end and the Terra \VM is the 
\emph{code generation phase}, which here outputs assembly instructions for the 
\VM, instead of statements in \C.
%
To reduce the memory footprint of applications, the \VM includes special 
instructions for complex and recurrent operations from the runtime of \CEU, 
such as handling events and trails.

In Terra, \CEU scripts cannot execute arbitrary \C code, instead, they rely on 
pre-built components that can be customized for different application domains.
%
Considering the domain of sensor networks, Terra already provides components 
organized in four areas: radio communication, group management, data 
aggregation, and local operations (e.g., access to sensors and actuators).
%
When creating an instance of the \VM, the programmer can choose whether or not 
to include each component, setting different abstraction boundaries for 
scripts.
%
The generated \VM has to be preloaded into the embedded devices before they are 
physically distributed.

The communication between scripts in \CEU and the components in the \VM is 
mostly through events:
scripts \code{emit} requests through \code{output} events and \code{await} 
answers through \code{input} events.
%
Terra also provides system calls for initialization and configuration of 
components (e.g., \emph{getters} and \emph{setters}).
%
Figure~\ref{lst.terra.defs}.a shows a \CEU interface with the available 
functionality for a customized \VM (with temperature and radio components).
Figure~\ref{lst.terra.defs}.b shows the associated bindings for output events 
(ln. 1--8), input events (ln. 10--14), and system calls (ln. 16--22).
%
Note that all applications for the customized \VM must comply with the same 
interface.
In contrast, the template-based \C back end (illustrated in 
Figure~\ref{lst.impl.tinyos}) allows applications to choose all possible 
combinations of functionalities from the underlying platform at compile time.

\begin{figure}
\begin{minipage}[t]{0.51\linewidth}
\begin{lstlisting}[morekeywords={function}]
// Output events
output void REQUEST_TEMPERATURE;
output int  REQUEST_SEND;    // sends int value

// Input events
input int  TEMPERATURE_DONE; // recvs int value
input void SEND_DONE;

// System calls
function int getRadioID (void);











.
\end{lstlisting}
\centering\small{(a)}
\end{minipage}
%
\begin{minipage}[t]{0.49\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=2.5em]
// Output events
void VM.out(int evt_id, void* args) {
    switch (id){
        case O_REQUEST_TEMPERATURE:
            call TINYOS_TEMP.read();
        <...>; // O_REQUEST_SEND
    }
}

// Input events
event TINYOS_TEMP.done (int val) {
    VM.enqueue(I_TEMPERATURE_DONE, &val);
}
<...> // TINYOS_SEND.done

// System calls
void VM.function(int id, void* params) {
    switch (id) {
        case F_GET_RADIO_ID:
            VM.push(TINYOS_NODE_ID);
    }
}
\end{lstlisting}
\centering\small{(b)}
\end{minipage}
%
\caption{
%{\small %\textmd{
(a) \CEU interface with customized \VM.
%
(b) The routine \code{VM.out} redirects all output events to the corresponding 
OS calls (ln.  1--8).
%
Each \emph{TinyOS} event callback calls \code{VM.enqueue} for the corresponding 
input event (ln 10--14).
%
System calls use \code{VM.push} for immediate return values (ln. 16--22).
%
\label{lst.terra.defs}
}
\end{figure}

\begin{comment}
Basically, they map

Basically, it is composed by instructions to define a pending trail (\code{tkins}),
a pending event(using \code{set\_c} to set a value in the memory),
a check operation to verify the \code{par/and} termination(\code{chkret}),
a pending timer event (\code{clken}), and some others like to clear trails data or suspend execution.
All pending entries are managed by the scheduler, that also responds for timer and input events.
All trails are executed as a TinyOS task, this ensure that each trail runs to completion avoiding race condition between then.

During compilation process the script is broken in trails in the same way it is 
done in the \CEU compiler explained in Section 4.
The Terra virtual machine implements a similar \CEU scheduler to execute the 
script trails, but the VM
uses the real trails address instead of labels. In this way is possible to jump directly to each script
partitions without using a dispatcher.

Figure~\ref{lst.impl.assembly} presents the bytecode generated for the initial 
part for the example of Figure~\ref{lst.impl.trails}.
After initializing the trail and event slots in the memory, the VM engine starts the execution from the \code{main} label.
In this example it registers in the trails slots the label addresses for the two block of the \code{par/and} control (lines 3--6).
The scheduler, first, executes the code in the label \code{and\_sub\_1} that registers the label \code{awk\_e} into the slot of event \code{e} (lines 8--10).
Then, executes the code in the label \code{and\_sub\_2} that registers the label \code{awk\_temp} into the slot of the event \code{I\_TEMP} (lines 17--18).
In this moment the VM engine suspends its execution waiting for some new input or timer event.
In the case of this example, the engine waits for the \code{I\_TEMP} event to continue the script execution.


\begin{figure}
\begin{minipage}[t]{0.91\linewidth}
\begin{lstlisting}[language=C,numbers=left,xleftmargin=2.5em,keywords={tkins,end,set_c,ushort,ubyte,exec}]
  <...> // Initializes the trails and events slots

:main -- Activate TRAILs 0 & 1
  tkins and_sub_1           // Activate TRAIL 0 - lbl and_sub_1
  tkins and_sub_2           // Activate TRAIL 1 - lbl and_sub_2
  end                       // Suspend execution

:and_sub_1
  set_c ushort slot_e awk_e // await e
  end                       // Suspend execution

:awk_e
  set_c ubyte slot_1 1      // Close TRAIL 0 - lbl and_sub_1
  exec chkret               // goto check par/and termination

:and_sub_2
  set_c ushort I_TEMP awk_temp // await TEMP
  end                       // Suspend execution

  <....> // Other entries: chkret, awk_TEMP, etc..
\end{lstlisting}
\end{minipage}
\caption{
%{\small %\textmd{
Assembly code for a \code{par/and} control structure.
%}%}
\label{lst.impl.assembly}
}
\end{figure}

Instead of generating code in \C, Terra generates the vmt assembly code using 
the original \CEU labels for trails entry points.
In the final phase for code generation, Terra compiler generates the vmt 
bytecode file using the program address in place of \CEU labels.
The use of address allows the \CEU scheduler to execute directly a trail 
without a index table to replace the switch-case.
Related to memory layout and trail allocation, Terra uses the same data 
organization approach for all \CEU controls and variables.
All \CEU data and control structures for a specific program are determined at 
compile time.
Terra arranges all these structures in the beginning of virtual machine memory 
space.
The original \CEU run time control functions are maintained with a small 
modification where accesses to control structures have an off-set relative to 
the begin of the virtual machine memory space.
\end{comment}

\section{Related Work}
\label{sec.related}

%\emph{(As subsecoes serao retiradas do texto ao final...)}

%\subsection{Semantics}

\CEU has a strong influence from Esterel, embracing its disciplined 
synchronous-reactive model with support for lexical composition of lines of 
execution.
%
However, there are fundamental semantic differences that prevents the design of 
\CEU as pure extensions to Esterel.
%
In particular, Esterel has a notion of time similar to digital circuits in 
which multiple signals can be active at a clock tick.
%In fact, Esterel is also used in hardware design.
%
In \CEU, instead of clock ticks, the occurrence of a single external event that 
defines a time unit.
%
\CEU also distinguishes external events from stack-based internal events, which 
provide a limited form of coroutines supporting reactive statements.

The event-driven approach of \CEU is widespread~\cite{sync_async.whynotthreads} 
and popular in many software communities, such as web frameworks (e.g., 
\emph{jQuery}~\cite{js.jquery} and \emph{Node.js}~\cite{js.node}), GUI toolkits 
(e.g., \emph{Tcl/Tk}~\cite{tcl.tk} and \emph{Java Swing}~\cite{java.swing}), 
and Games~\cite{gamepatterns}.
%
Like \CEU, event-driven programming is essentially synchronous, i.e., events go 
through a queue and are dispatched sequentially and atomically to prevent race 
conditions.
%
We believe that for software design, this approach is more familiar to 
programmers and simplifies the reasoning about concurrency.
For instance, the uniqueness of external events in \CEU is a prerequisite for 
the temporal analysis that enables safe shared-memory concurrency.

Many synchronous languages have been designed to interoperate with \C, such as 
\emph{Reactive C}~\cite{rp.rc}, Protothreads~\cite{wsn.protothreads}, 
\emph{PRET-C}~\cite{rp.pretc} and \emph{SC}~\cite{rp.synchc}.
%
They offer Esterel-like parallel compositions with communication via shared 
variables, relying on deterministic scheduling to preserve determinism.
%
However, it is the responsibility of the programmer to specify the execution 
order for threads, based on either explicit priorities, or source code lexical 
order (similar to \CEU).
%
These languages have a tick-based notion of time similar to Esterel, which 
prevents the event-based temporal analysis of \CEU.

\emph{URBI}~\cite{rp.urbi} is a reactive scripting language with a rich set of 
control constructs for time management, event-driven communication, and 
concurrency.
Concurrency is based on stackful coroutines, diverging from our goals regarding 
resource efficiency and static bounds for memory and execution time.

%\subsection{Implementation}

Esterel has different compilation back ends that synthesizes to software and 
also to hardware circuits~\cite{esterel.emperor,esterel.tutorial}.
Among the software-based approaches, \emph{SAXO--RT}~\cite{esterel.saxort} is 
the closest to our implementation with respect to trail allocation and 
scheduling:
the compiler slices programs into ``control points'' (analogous to our ``entry 
points'') and rearranges them into a directed acyclic graph respecting the 
constructive semantics of Esterel.
Then, it flattens the graph into sequential code in \C suitable for static 
scheduling.

%\subsection{VM}

A number of virtual machines have been proposed for embedded systems.
%
%The \emph{Sun SPOT} platform with the \emph{Squawk JVM} brings Java for the 
%embedded domain~\cite{wsn.sunspot}, but requires a much powerful hardware.%
%\footnote{The \emph{Sun SPOT} uses a 32-bit CPU with 4 Mbytes of FLASH and 512 
%KBytes of SRAM.}
%
\emph{Darjeeling}~\cite{wsn.darjeeling} and \emph{TakaTuka}~\cite{wsn.takatuka} 
are complete \emph{Java VMs} targeting constrained embedded systems with 
support for multithreading and garbage collection.
%
Java has antagonistic design choices in comparison to \CEU:
it does not impose static bounds on memory usage and execution time, and 
provides preemptive multithreading which requires synchronization primitives 
for accessing shared memory.
%
Plummer et al.~\cite{esterel.vm} propose a Esterel-based \VM with similar 
design choices to our work.
To reduce code size, the \VM has a specialized instruction set to deal with 
events and concurrency constructs that are particular to Esterel.
However, the proposed \VM is only a proof of concept, with no support for 
arithmetic operations, external system calls, or remote reprogramming.

\begin{comment}
- Kiel Esterel compiler

- We are not concerned with WCET:
Predictable system design is concerned with the challenge o
f building sys-
tems in such a way that requirements can be guaranteed from th
e design. This
means that an off-line analysis should demonstrate satisfa
ction of timing require-
ments, subject to assumptions made on operating conditions
foreseen for the sys-
tem [Stankovic and Ramamritham 1990]

http://embedded.cs.uni-saarland.de/publications/BuildingTimingPredictableEmbeddedSystems.pdf
survey of timeing-predictable embedded systems,
synchronous languages do some at the lang semantic level
\cite{pret.building}
\end{comment}

\section{Conclusion}
\label{sec.conclusion}

We presented the design, semantics, and implementation of \CEU, a synchronous 
reactive language inspired by Esterel targeting constrained embedded systems.

\CEU is a concurrency-safe language, employing a static analysis that encompass 
all control constructs and ensures that the high degree of concurrency in 
embedded systems does not pose safety threats to applications.
%
As a summary, the following safety properties hold for all programs that 
successfully compile in \CEU:
time and memory-bounded reactions to the environment (except for external 
system calls),
no race conditions in shared memory,
reliable abortion for activities handling resources,
and automatic synchronization for timers.
%
These properties are usually desirable in embedded applications and are 
guaranteed as preconditions in \CEU by design.

\CEU is a resource-efficient language suitable for constrained embedded 
systems.
The reference implementation compiles to portable event-driven code in \C, with 
no special requirements for OS threads or per-trail data stacks.
The \VM implementation uses the same front end and imposes no extra 
restrictions, being equally suitable for constrained systems.

\CEU is a practical language with expressive control constructs, such as 
lexically scoped parallel compositions, convenient first-class timers, and a 
unique stack-based signaling mechanism.
%
Programs interoperate seamlessly with \C, and can take advantage of existing 
libraries, lowering the entry barrier for adoption.
%
\CEU has an open source implementation and bindings for \emph{TinyOS}, 
\emph{Arduino}, and the \emph{SDL} graphical library.%
\footnote{Website of \CEU: \url{http://www.ceu-lang.org/}}

For the past three years, we have been teaching \CEU for undergraduate and 
graduate students in research projects and two hands-on courses on 
\emph{distributed systems} and \emph{reactive programming}.
%, in which the studnets designing protocols, embedded systems, and graphical 
%applications.
%
Our experience shows that students take advantage of the sequential-imperative 
style of \CEU and can implement non-trivial concurrent applications in a few 
weeks.

% Idexx

\begin{comment}
We are also extending and applying \CEU in more dynamic domains, such as GUIs 
and games~\cite{ceu.mod15}, by relaxing some restrictions in the language.
In particular, programs in these domains typically require unbounded memory and 
execution time, such as for dealing with dynamic collections.
We provide unsafe annotations to circumvent the rigid semantics of \CEU, 
requiring them to be explicit and trackable at the same time.
\end{comment}

% Bibliography
\bibliographystyle{ACM-Reference-Format-Journals}
\bibliography{my,other,terra}
                             % Sample .bib file with references that match those in
                             % the 'Specifications Document (V1.5)' as well containing
                             % 'legacy' bibs and bibs with 'alternate codings'.
                             % Gerry Murray - March 2012

% History dates
%\received{February 2007}{March 2009}{June 2009}

% Electronic Appendix
%\elecappendix

%\medskip

\end{document}
% End of v2-acmsmall-sample.tex (March 2012) - Gerry Murray, ACM
